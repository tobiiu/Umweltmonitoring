services:
  db:
    image: timescale/timescaledb:latest-pg15
    container_name: timescaledb
    environment:
      POSTGRES_USER: user # Change this if needed
      POSTGRES_PASSWORD: password # Change this if needed
      POSTGRES_DB: env_monitoring
    ports:
      - "5434:5432" # Map host port 5434 to container port 5432 (PostgreSQL default)
    volumes:
      - timescaledb_data:/var/lib/postgresql/data # Persist database data
      - ./init-db:/docker-entrypoint-initdb.d # Run initialization scripts (e.g., .sql files)
    healthcheck:
        test: ["CMD-SHELL", "pg_isready -U user -d env_monitoring"]
        interval: 5s
        timeout: 5s
        retries: 5

  # Service for collecting data from openSenseMap API
  data_collector:
    build:
      context: ./data_collector # Specifies the build context (directory for Dockerfile)
      dockerfile: Dockerfile
    container_name: sensebox_data_collector
    environment:
      SENSEBOX_ID: "60d828c48855dd001cf91983" # Pass SenseBox ID to sensebox.py
    volumes:
      - ./data:/app/data # Mounts the host's ./data directory to /app/data inside the container
    depends_on:
      db: # Optional: Ensure DB is healthy if data_collector might write to it in the future
        condition: service_healthy

  # Service for the Dash web application
  app:
    build:
      context: ./app # Specifies the build context (directory for Dockerfile)
      dockerfile: Dockerfile
    container_name: dash_app
    ports:
      - "8050:8050" # Map host port 8050 to container port 8050 (Dash default)
    environment:
      DB_USER: user
      DB_PASSWORD: password
      DB_HOST: db # Service name from docker-compose
      DB_PORT: 5432 # Internal port of the DB container
      DB_NAME: env_monitoring
      SENSEBOX_ID: "60d828c48855dd001cf91983" # Pass SenseBox ID to app.py
    volumes:
      - ./data:/app/data # Mount the same shared volume for data.csv
    depends_on:
      db:
        condition: service_healthy # Ensure DB is healthy
      data_collector: # Ensure data collector has started (so data.csv can be created)
        condition: service_started

volumes:
  timescaledb_data: {} # Defines the named volume for TimescaleDB data
  # You could also define a named volume for 'data' here if you prefer:
  # data_volume: {}